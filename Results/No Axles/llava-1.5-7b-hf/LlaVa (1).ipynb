{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UgyXFQ3Pmdjq",
    "outputId": "f04d9153-109a-4f23-b7df-9a4ca8f3b95b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.11/site-packages (0.45.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.47.1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (1.2.1)\n",
      "Requirement already satisfied: codecarbon in /opt/conda/lib/python3.11/site-packages (2.8.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (2.5.1+cu124)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (2.1.2)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: arrow in /opt/conda/lib/python3.11/site-packages (from codecarbon) (1.3.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from codecarbon) (8.1.7)\n",
      "Requirement already satisfied: fief-client[cli] in /opt/conda/lib/python3.11/site-packages (from codecarbon) (0.20.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from codecarbon) (2.2.3)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.11/site-packages (from codecarbon) (0.21.0)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.11/site-packages (from codecarbon) (9.0.0)\n",
      "Requirement already satisfied: pynvml in /opt/conda/lib/python3.11/site-packages (from codecarbon) (12.0.0)\n",
      "Requirement already satisfied: questionary in /opt/conda/lib/python3.11/site-packages (from codecarbon) (2.0.1)\n",
      "Requirement already satisfied: rapidfuzz in /opt/conda/lib/python3.11/site-packages (from codecarbon) (3.11.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from codecarbon) (13.9.4)\n",
      "Requirement already satisfied: typer in /opt/conda/lib/python3.11/site-packages (from codecarbon) (0.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /opt/conda/lib/python3.11/site-packages (from arrow->codecarbon) (2.9.0.post0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.11/site-packages (from arrow->codecarbon) (2.9.0.20241003)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.21.3 in /opt/conda/lib/python3.11/site-packages (from fief-client[cli]->codecarbon) (0.27.2)\n",
      "Requirement already satisfied: jwcrypto<2.0.0,>=1.4 in /opt/conda/lib/python3.11/site-packages (from fief-client[cli]->codecarbon) (1.5.6)\n",
      "Requirement already satisfied: yaspin in /opt/conda/lib/python3.11/site-packages (from fief-client[cli]->codecarbon) (3.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->codecarbon) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->codecarbon) (2024.2)\n",
      "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /opt/conda/lib/python3.11/site-packages (from pynvml->codecarbon) (12.560.30)\n",
      "Requirement already satisfied: prompt_toolkit<=3.0.36,>=2.0 in /opt/conda/lib/python3.11/site-packages (from questionary->codecarbon) (3.0.36)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->codecarbon) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->codecarbon) (2.18.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.11/site-packages (from typer->codecarbon) (1.5.4)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.11/site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.7)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.14.0)\n",
      "Requirement already satisfied: cryptography>=3.4 in /opt/conda/lib/python3.11/site-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (44.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt_toolkit<=3.0.36,>=2.0->questionary->codecarbon) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
      "Requirement already satisfied: termcolor<2.4.0,>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from yaspin->fief-client[cli]->codecarbon) (2.3.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.11/site-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.22)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes transformers accelerate codecarbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o2vP9MtDmuLm",
    "outputId": "4cc26d3d-2c8e-404d-8096-6395d1cd481e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'benchmark_vlm' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/muqtasid87/benchmark_vlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "plFroaGkxr7n"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers.image_utils import load_image\n",
    "import torch\n",
    "import csv\n",
    "import platform\n",
    "from transformers import pipeline\n",
    "import psutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from codecarbon import EmissionsTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "b1bb1d4ece4c4ff3a8ff1ee5fdfb0618",
      "90b2203f9765423dae5163be4cd25c63",
      "6a37f8d206ad4c8ba487432b2cb35c1e",
      "d62940efbc1440fc95fa5e8c378334db",
      "cc3c5ef95e43420db3f5584842f0fae5",
      "0576428afc964b3486a9c3838dda4d08",
      "24251d912a7047348dbbc4503b1ed3e7",
      "4f98ca22c7ad4384b50fc54bf35ed247",
      "b4920ec582ba4ae29faf26908fdcd871",
      "bafec53c91ac46b79e4b10587a7457bb",
      "83044e0c698a47a991db9845be8a9e68"
     ]
    },
    "id": "hdmdVbNBxaZl",
    "outputId": "11d5ec8f-59a5-44c4-a0a7-b4f9b64f923d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1ccaf03e064d92b1a4e69f0c917710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/950 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b547128dc24cd99af38062c0e42087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/70.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02df37b51584d7498186a7aec70aeb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7d06ab8e104f649b29619ffe4ad14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:651: UserWarning: Not enough free disk space to download the file. The expected file size is: 4957.88 MB. The target location /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/blobs only has 3340.85 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6944b96b254c47bd86d98cd2114861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade912fe9a0c44689123fc7174422712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:651: UserWarning: Not enough free disk space to download the file. The expected file size is: 4957.88 MB. The target location /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/blobs only has 1.89 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb9dd3fca3d43e38426499a89aa8113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:  67%|######7   | 3.34G/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Could not load model llava-hf/llava-1.5-7b-hf with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForVision2Seq'>, <class 'transformers.models.llava.modeling_llava.LlavaForConditionalGeneration'>). See the original errors:\n\nwhile loading with AutoModelForVision2Seq, an error is thrown:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 289, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\", line 564, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 3990, in from_pretrained\n    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\n                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/transformers/utils/hub.py\", line 1098, in get_checkpoint_shard_files\n    cached_filename = cached_file(\n                      ^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/transformers/utils/hub.py\", line 403, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 860, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1009, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1543, in _download_to_tmp_and_move\n    http_get(\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 455, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\nwhile loading with LlavaForConditionalGeneration, an error is thrown:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 289, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 3990, in from_pretrained\n    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\n                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/transformers/utils/hub.py\", line 1098, in get_checkpoint_shard_files\n    cached_filename = cached_file(\n                      ^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/transformers/utils/hub.py\", line 403, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 860, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1009, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1543, in _download_to_tmp_and_move\n    http_get(\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 455, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m quantization_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(\n\u001b[1;32m      3\u001b[0m     load_in_4bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m     bnb_4bit_compute_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllava-hf/llava-1.5-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage-to-text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquantization_config\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m processor \u001b[38;5;241m=\u001b[39m AutoProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/__init__.py:940\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    939\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 940\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    950\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    951\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/base.py:302\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m class_name, trace \u001b[38;5;129;01min\u001b[39;00m all_traceback\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    301\u001b[0m             error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile loading with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, an error is thrown:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 302\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    303\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not load model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with any of the following classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_tuple\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. See the original errors:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m         )\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     framework \u001b[38;5;241m=\u001b[39m infer_framework(model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not load model llava-hf/llava-1.5-7b-hf with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForVision2Seq'>, <class 'transformers.models.llava.modeling_llava.LlavaForConditionalGeneration'>). See the original errors:\n\nwhile loading with AutoModelForVision2Seq, an error is thrown:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 289, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\", line 564, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 3990, in from_pretrained\n    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\n                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/transformers/utils/hub.py\", line 1098, in get_checkpoint_shard_files\n    cached_filename = cached_file(\n                      ^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/transformers/utils/hub.py\", line 403, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 860, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1009, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1543, in _download_to_tmp_and_move\n    http_get(\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 455, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\nwhile loading with LlavaForConditionalGeneration, an error is thrown:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 289, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 3990, in from_pretrained\n    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\n                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/transformers/utils/hub.py\", line 1098, in get_checkpoint_shard_files\n    cached_filename = cached_file(\n                      ^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/transformers/utils/hub.py\", line 403, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 860, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1009, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1543, in _download_to_tmp_and_move\n    http_get(\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 455, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\n\n"
     ]
    }
   ],
   "source": [
    "# Load model and processor\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "pipe = pipeline(\"image-to-text\", model=model_id, model_kwargs={\"quantization_config\": quantization_config})\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L10lGQF8yCdE"
   },
   "outputs": [],
   "source": [
    "# Image directory\n",
    "img_dir = 'benchmark_vlm/master'\n",
    "use_axles = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bX_KB6JTrGw4"
   },
   "outputs": [],
   "source": [
    "wrong_predictions_dir = f'experiment_data/{model_id}/wrong_predictions'  # Directory to store wrongly predicted images\n",
    "os.makedirs(wrong_predictions_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8k86dXQJ9_81"
   },
   "source": [
    "### Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDIEGC215lsG"
   },
   "outputs": [],
   "source": [
    "# Function to run inference\n",
    "def infer_image(image_path, prompt):\n",
    "  conversation = [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "            {\"type\": \"image\"},\n",
    "          ],\n",
    "      },\n",
    "  ]\n",
    "  prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "  with open(image_path, \"rb\") as f:\n",
    "      input_image = Image.open(f).convert(\"RGB\")\n",
    "\n",
    "      outputs = pipe(input_image, prompt=prompt, generate_kwargs={\"max_new_tokens\": 2})\n",
    "      outputs = outputs[0][\"generated_text\"]\n",
    "      outputs = outputs.split(\"ASSISTANT: \", 1)[-1]\n",
    "\n",
    "  return outputs.lower() #outputs only vlm response token in string format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kymovqsQ99A_"
   },
   "source": [
    "### Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NM8O5ht0-G9x"
   },
   "outputs": [],
   "source": [
    "# Define vehicle classes for validation\n",
    "vehicle_classes = {\n",
    "    \"Class 1 - Motorcycles\": [\"motorcycle\", \"motorbike\", \"bike\", \"scooter\", \"motor\", \"moped\"],\n",
    "    \"Class 2 - Car, SUV, Station Wagons\": [\"car\", \"sedan\", \"hatchback\", \"suv\", \"mpv\", \"crossover\", \"station wagon\", \"wagon\", \"coupe\"],\n",
    "    \"Class 3 - 2 axle lorry, van, pickup\": [\"pickup\", \"van\", \"minivan\"],\n",
    "    \"Class 4 - 2 axles, 5 or 6 wheels bus or truck\": [\"bus\", \"truck\", 'trailer', 'lorry', 'tractor', 'tanker', 'dump truck', \"tow truck\", \"dump trailer\"],\n",
    "    \"Class 5 - 3 axle truck, bus\": [\"bus\", \"truck\"],\n",
    "    \"Class 6 - 4 axles\": [\"coach\", \"bus\", \"truck\", 'trailer', 'lorry', 'tractor', 'tanker', 'dump truck', \"tow truck\", \"dump trailer\"],\n",
    "    \"Class 7 - 5 or more axles\": [\"coach\", \"bus\", \"truck\", 'trailer', 'lorry', 'tractor', 'tanker', 'dump truck', \"tow truck\", \"dump trailer\"],\n",
    "    \"bus 2\" : [\"coach\", \"bus\"],\n",
    "    \"bus 3\" : [\"coach\", \"bus\"],\n",
    "    \"truck 2\" : [\"truck\", 'trailer', 'lorry', 'tractor', 'tanker', 'dump truck', \"tow truck\", \"dump trailer\"],\n",
    "    \"truck 3\" : [\"truck\", 'trailer', 'lorry', 'tractor', 'tanker', 'dump truck', \"tow truck\", \"dump trailer\"],\n",
    "    \"truck 4\" : [\"truck\", 'trailer', 'lorry', 'tractor', 'tanker', 'dump truck', \"tow truck\", \"dump trailer\"],\n",
    "    \"truck 5\" : [\"truck\", 'trailer', 'lorry', 'tractor', 'tanker', 'dump truck', \"tow truck\", \"dump trailer\"],\n",
    "    \"van\" : [\"van\", \"minivan\", 'minibus'],\n",
    "    \"pickup\" : [\"pickup\", \"pickup truck\", \"camper\"],\n",
    "}\n",
    "\n",
    "valid_vehicle_types = {type for sublist in vehicle_classes.values() for type in sublist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thh669gy5oLj"
   },
   "outputs": [],
   "source": [
    "# Validate predictions\n",
    "\n",
    "def validate_prediction(folder_name, prediction, axles=None):\n",
    "    # Extract folder label\n",
    "    for class_name, valid_labels in vehicle_classes.items():\n",
    "        if folder_name.startswith(class_name):\n",
    "            if axles:  # Use axle count for bus/truck\n",
    "                if axles == 1 or 0:\n",
    "                  return False\n",
    "                elif axles == 2:\n",
    "                    return \"2\" in folder_name[-1]\n",
    "                elif axles == 3:\n",
    "                    return \"3\" in folder_name[-1]\n",
    "                elif axles == 4:\n",
    "                    return \"4\" in folder_name[-1]\n",
    "                elif axles >= 5:\n",
    "                    return \"5\" in folder_name[-1]\n",
    "            if isinstance(valid_labels, list):\n",
    "                return prediction in valid_labels\n",
    "            return prediction == valid_labels\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYX4uILS97b0"
   },
   "source": [
    "# Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZUPwlG9pQWa"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "as1UY4lBj0Ha",
    "outputId": "f9ad3083-6ca0-4936-a442-0dc4b964b89a"
   },
   "outputs": [],
   "source": [
    "# Main processing loop\n",
    "total_files = sum(len(files) for _, _, files in os.walk(img_dir))\n",
    "progress_bar = tqdm(total=total_files, desc=\"Processing Images\", unit=\"file\")\n",
    "start_time = time.time()\n",
    "tracker = EmissionsTracker()\n",
    "tracker.start()\n",
    "results = []\n",
    "for root, dirs, files in os.walk(img_dir):\n",
    "    for file in files:\n",
    "        if file.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "            image_path = os.path.join(root, file)\n",
    "            folder_name = os.path.basename(os.path.dirname(image_path))\n",
    "            progress_bar.set_description(f\"Processing: {folder_name}\")\n",
    "            progress_bar.update(1)  # Increment the progress bar\n",
    "            print(f\"Processing: {folder_name}\")\n",
    "\n",
    "            try:\n",
    "                # First inference: vehicle type\n",
    "                vehicle_prompt = f\"What type of vehicle is this?  Answer in one word\"\n",
    "                # vehicle_prompt = f\"What type of vehicle is this? Choose one from: {', '.join(valid_vehicle_types)}. Answer in one word\"\n",
    "                prediction = infer_image(image_path, vehicle_prompt)\n",
    "                print(f\"Vehicle Prediction: {prediction}\")\n",
    "\n",
    "                # Handle buses and trucks\n",
    "                axles = None\n",
    "                if prediction in [\"bus\", \"truck\", 'trailer', 'lorry', 'tractor', 'tanker', 'dump truck',  \"tow truck\", \"dump trailer\"]:\n",
    "                    # Check if it's a pickup truck\n",
    "                    if prediction == 'truck':\n",
    "                        pickup_prompt = \"Is this a pickup truck? Respond with only yes or no.\"\n",
    "                        is_pickup = infer_image(image_path, pickup_prompt).strip().lower()\n",
    "                        print(f\"Is Pickup Truck: {is_pickup}\")\n",
    "                        if is_pickup == \"yes\":\n",
    "                            prediction = \"pickup truck\"\n",
    "                        elif use_axles:\n",
    "                            # Predict axles for non-pickup trucks\n",
    "                            axle_prompt = \"How many axles does this vehicle have? Output a single integer value.\"\n",
    "                            axle_prediction = infer_image(image_path, axle_prompt)\n",
    "                            print(f\"Axle Prediction: {axle_prediction}\")\n",
    "\n",
    "                            try:\n",
    "                                axles = int(axle_prediction)\n",
    "                            except ValueError:\n",
    "                                print(f\"Invalid axle prediction: {axle_prediction}\")\n",
    "                                axles = None  # Fallback if parsing fails\n",
    "                    elif use_axles:\n",
    "\n",
    "                      axle_prompt = \"How many axles does this vehicle have? Output a single integer value\"\n",
    "                      axle_prediction = infer_image(image_path, axle_prompt)\n",
    "                      print(f\"Axle Prediction: {axle_prediction}\")\n",
    "\n",
    "                      try:\n",
    "                          axles = int(axle_prediction)\n",
    "                      except ValueError:\n",
    "                          print(f\"Invalid axle prediction: {axle_prediction}\")\n",
    "\n",
    "                # Validate prediction\n",
    "                is_correct = validate_prediction(folder_name, prediction, axles)\n",
    "                print(f\"Validation Result: {is_correct}\")\n",
    "\n",
    "                # Store results\n",
    "                results.append({\n",
    "                    \"image\": image_path,\n",
    "                    \"folder_label\": folder_name,\n",
    "                    \"prediction\": prediction,\n",
    "                    \"axles\": axles,\n",
    "                    \"is_correct\": is_correct\n",
    "                })\n",
    "\n",
    "                # Handle wrong predictions\n",
    "                if not is_correct:\n",
    "                    # Create a folder for the wrong prediction\n",
    "                    wrong_folder = os.path.join(wrong_predictions_dir, prediction, str(axles))\n",
    "                    os.makedirs(wrong_folder, exist_ok=True)\n",
    "\n",
    "                    # Copy the image to the folder\n",
    "                    shutil.copy(image_path, os.path.join(wrong_folder, file))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "                continue\n",
    "emissions = tracker.stop()\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Total processing time: {elapsed_time:.2f} seconds\")\n",
    "print(f\"CO2 emissions: {emissions:.6f} kg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deuWnIycM0q-"
   },
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "output_csv = f'experiment_data/{model_id}/results.csv'\n",
    "with open(output_csv, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"image\", \"folder_label\", \"prediction\", \"axles\", \"is_correct\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "# Metrics calculation\n",
    "correct_predictions = sum(1 for r in results if r[\"is_correct\"])\n",
    "total_images = len(results)\n",
    "accuracy = correct_predictions / total_images * 100 if total_images > 0 else 0\n",
    "wrong_predictions = total_images - correct_predictions\n",
    "\n",
    "# Per-class metrics\n",
    "class_metrics = {}\n",
    "for result in results:\n",
    "    label = result[\"folder_label\"]\n",
    "    correct = result[\"is_correct\"]\n",
    "    if label not in class_metrics:\n",
    "        class_metrics[label] = {\"correct\": 0, \"total\": 0}\n",
    "    class_metrics[label][\"total\"] += 1\n",
    "    if correct:\n",
    "        class_metrics[label][\"correct\"] += 1\n",
    "\n",
    "# Aggregate class metrics\n",
    "per_class_accuracy = {\n",
    "    label: (data[\"correct\"] / data[\"total\"]) * 100\n",
    "    for label, data in class_metrics.items()\n",
    "}\n",
    "per_class_error_rate = {\n",
    "    label: 100 - acc for label, acc in per_class_accuracy.items()\n",
    "}\n",
    "\n",
    "# Collect system configuration\n",
    "system_config = {\n",
    "    \"Processor\": platform.processor(),\n",
    "    \"CPU Count\": psutil.cpu_count(logical=True),\n",
    "    \"Memory (GB)\": round(psutil.virtual_memory().total / (1024 ** 3), 2),\n",
    "    \"Elapsed Time (seconds)\": elapsed_time,\n",
    "    \"CO2 Emissions (kg)\": round(emissions, 6)\n",
    "}\n",
    "\n",
    "# Metrics dictionary\n",
    "metrics = {\n",
    "    \"Total Images\": total_images,\n",
    "    \"Correct Predictions\": correct_predictions,\n",
    "    \"Wrong Predictions\": wrong_predictions,\n",
    "    \"Accuracy (%)\": accuracy,\n",
    "    \"Error Rate (%)\": 100 - accuracy\n",
    "}\n",
    "\n",
    "# Save metrics to CSV\n",
    "metrics_csv =  f'experiment_data/{model_id}/metrics.csv'\n",
    "with open(metrics_csv, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Model\", \"Metric\", \"Value\"])\n",
    "    for key, value in metrics.items():\n",
    "        writer.writerow([model_id, key, value])\n",
    "    for label, acc in per_class_accuracy.items():\n",
    "        writer.writerow([model_id, f\"Per-Class Accuracy: {label}\", acc])\n",
    "        writer.writerow([model_id, f\"Per-Class Error Rate: {label}\", per_class_error_rate[label]])\n",
    "    for key, value in system_config.items():\n",
    "        writer.writerow([model_id, key, value])\n",
    "\n",
    "# Print final metrics\n",
    "print(\"\\n--- Metrics ---\")\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "for label, acc in per_class_accuracy.items():\n",
    "    print(f\"Class '{label}' - Accuracy: {acc:.2f}%, Error Rate: {per_class_error_rate[label]:.2f}%\")\n",
    "for key, value in system_config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0576428afc964b3486a9c3838dda4d08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24251d912a7047348dbbc4503b1ed3e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f98ca22c7ad4384b50fc54bf35ed247": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a37f8d206ad4c8ba487432b2cb35c1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f98ca22c7ad4384b50fc54bf35ed247",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b4920ec582ba4ae29faf26908fdcd871",
      "value": 3
     }
    },
    "83044e0c698a47a991db9845be8a9e68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "90b2203f9765423dae5163be4cd25c63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0576428afc964b3486a9c3838dda4d08",
      "placeholder": "",
      "style": "IPY_MODEL_24251d912a7047348dbbc4503b1ed3e7",
      "value": "Loadingcheckpointshards:100%"
     }
    },
    "b1bb1d4ece4c4ff3a8ff1ee5fdfb0618": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_90b2203f9765423dae5163be4cd25c63",
       "IPY_MODEL_6a37f8d206ad4c8ba487432b2cb35c1e",
       "IPY_MODEL_d62940efbc1440fc95fa5e8c378334db"
      ],
      "layout": "IPY_MODEL_cc3c5ef95e43420db3f5584842f0fae5"
     }
    },
    "b4920ec582ba4ae29faf26908fdcd871": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bafec53c91ac46b79e4b10587a7457bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc3c5ef95e43420db3f5584842f0fae5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d62940efbc1440fc95fa5e8c378334db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bafec53c91ac46b79e4b10587a7457bb",
      "placeholder": "",
      "style": "IPY_MODEL_83044e0c698a47a991db9845be8a9e68",
      "value": "3/3[01:12&lt;00:00,23.56s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
